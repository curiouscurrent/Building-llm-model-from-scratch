{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78d9402-492a-4d62-9701-b2685921fa69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlzma\u001b[39;00m \u001b[38;5;66;03m#for handling xz files -> these are compressed files\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;66;03m# for displaying a progress bar (moving from left to right)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#takes directory as an input and returns a list of all the xz file names in that directory\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#it uses os.listdir to get a list of file names\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#os.path.isfile - to check if its a file and not a dir and if it ends with .xz\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mxz_files_in_dir\u001b[39m(directory):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------\n",
    "#tqdm not working \n",
    "# so refer the code in the next cell\n",
    "#--------------------------------------------------------------\n",
    "import os\n",
    "import lzma #for handling xz files -> these are compressed files\n",
    "import tqdm # for displaying a progress bar (moving from left to right)\n",
    "\n",
    "#takes directory as an input and returns a list of all the xz file names in that directory\n",
    "#it uses os.listdir to get a list of file names\n",
    "#os.path.isfile - to check if its a file and not a dir and if it ends with .xz\n",
    "def xz_files_in_dir(directory):\n",
    "    files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xz\") and os.path.isfile(os.path.join(directory, filename)):\n",
    "            files.append(filename)\n",
    "    return files\n",
    "\n",
    "folder_path = \"D:\\\\openwebtext\\\\openwebtext\"\n",
    "output_file_train = \"output_train.txt\" #90% of data\n",
    "output_file_val = \"output_val.txt\" #10% of data\n",
    "vocab_file = \"vocab.txt\" #all new characters from the giant corpus will be pushed here.\n",
    "\n",
    "files = xz_files_in_dir(folder_path) #list of file names stored in this variable\n",
    "total_files = len(files)\n",
    "\n",
    "# Calculate the split indices\n",
    "split_index = int(total_files * 0.9) # 90% for training\n",
    "files_train = files[:split_index]\n",
    "files_val = files[split_index:]\n",
    "\n",
    "# Process the files for training and validation separately\n",
    "vocab = set() #set is a collection of unique items (here new chars in giant corpus)\n",
    "\n",
    "# Process the training files\n",
    "with open(output_file_train, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for filename in tqdm(files_train, total=len(files_train)):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as infile:\n",
    "            text = infile.read()\n",
    "            outfile.write(text)\n",
    "            characters = set(text)\n",
    "            vocab.update(characters)\n",
    "\n",
    "# Process the validation files\n",
    "with open(output_file_val, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for filename in tqdm(files_val, total=len(files_val)):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as infile:\n",
    "            text = infile.read()\n",
    "            outfile.write(text)\n",
    "            characters = set(text)\n",
    "            vocab.update(characters)\n",
    "\n",
    "# Write the vocabulary to vocab.txt\n",
    "with open(vocab_file, \"w\", encoding=\"utf-8\") as vfile:\n",
    "    for char in vocab:\n",
    "        vfile.write(char + '\\n')\n",
    "\n",
    "#write all characters in vocab to vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c623b25-3ad0-4762-80a4-91602de91efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c248215-9ea2-4f0e-81b0-a2c58e1af699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa07d40-a515-45d6-8892-abbefd5af07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary written to vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lzma\n",
    "\n",
    "# Function to get a list of all xz file names in a directory\n",
    "def xz_files_in_dir(directory):\n",
    "    files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xz\") and os.path.isfile(os.path.join(directory, filename)):\n",
    "            files.append(filename)\n",
    "    return files\n",
    "\n",
    "folder_path = \"D:\\\\openwebtext\\\\openwebtext\"\n",
    "output_file_train = \"output_train.txt\"  # 90% of data\n",
    "output_file_val = \"output_val.txt\"  # 10% of data\n",
    "vocab_file = \"vocab.txt\"  # all new characters from the giant corpus will be pushed here.\n",
    "\n",
    "files = xz_files_in_dir(folder_path)  # list of file names stored in this variable\n",
    "total_files = len(files)\n",
    "\n",
    "# Calculate the split indices\n",
    "split_index = int(total_files * 0.9)  # 90% for training\n",
    "files_train = files[:split_index]\n",
    "files_val = files[split_index:]\n",
    "\n",
    "# Process the files for training and validation separately\n",
    "vocab = set()  # set is a collection of unique items (here new chars in giant corpus)\n",
    "\n",
    "# Process the training files\n",
    "with open(output_file_train, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for filename in files_train:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as infile:\n",
    "            text = infile.read()\n",
    "            outfile.write(text)\n",
    "            characters = set(text)\n",
    "            vocab.update(characters)\n",
    "\n",
    "# Process the validation files\n",
    "with open(output_file_val, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for filename in files_val:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as infile:\n",
    "            text = infile.read()\n",
    "            outfile.write(text)\n",
    "            characters = set(text)\n",
    "            vocab.update(characters)\n",
    "\n",
    "# Write the vocabulary to vocab.txt without tqdm\n",
    "with open(vocab_file, \"w\", encoding=\"utf-8\") as vfile:\n",
    "    for char in vocab:\n",
    "        vfile.write(char + '\\n')\n",
    "\n",
    "print(\"Vocabulary written to\", vocab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2483ad97-7988-493f-9384-9b7dad98f671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LexaWeave",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
